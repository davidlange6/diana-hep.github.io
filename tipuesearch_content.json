{"pages":[{"url":"/","text":"PROJECT PERSONNEL Peter Elmer (Lead PI) - Princeton University Department of Physics Kyle Cranmer (Co-PI) - New York University Department of Physics & Center for Data Science Jinyang Li (Senior Personnel) - New York University Computer Science Department Michael D. Sokoloff (Co-PI) - University of Cincinnati Main Campus Department of Physics Brian P. Bockelman (Co-PI) - University of Nebraska-Lincoln Department of Computer Science and Engineering Advisory Board Amber Boehnlein - Head of Scientific Computing at SLAC National Accelerator Laboratory Katherine Copic - Director of Growth, Insight Data Science Jacob VanderPlas - Director of Research, Physical Sciences, eScience Institute, University of Washington Fernando Pérez - Staff Scientist, Data Science and Technology Division, Lawrence Berkeley National Laboratory; Associate Researcher, Berkeley Institute for Data Science, UC Berkeley. Attanagoda Santha - Architect, Fannie Mae Project Overview Advanced software plays a fundamental role for large scientific projects. The primary goal of DIANA/HEP (Data Intensive ANAlysis for High Energy Physics) is developing state-of-the-art tools for experiments which acquire, reduce, and analyze petabytes of data. Improving performance, interoperability, and collaborative tools through modifications and additions to packages broadly used by the community will allow users to more fully exploit the data being acquired at CERN's Large Hadron Collider (LHC) and other facilities. These experiments are addressing questions at the heart of physics -- what are the underlying constituents of matter and how do they interact. With the discovery of the Higgs boson in 2012, the Standard Model of particle physics is complete. It provides an excellent description of known particles and forces. However, the most interesting questions remain open: What is the dark matter which pervades the universe? Does space-time have additional symmetries or extend beyond the 3 spatial dimensions we know? What is the mechanism stabilizing the Higgs boson mass from enormous quantum corrections? The next generation of experiments will collect exabyte-scale data samples to provide answers. Analyzing this data will require new and better tools. To improve the quality of the next generation of software engineers in HEP, DIANA will host an annual workshop on analysis tools and establish a fellowship program. First, we will provide the CPU and IO performance needed to reduce the iteration time so crucial to explore new ideas. We will develop software to effectively exploit emerging many- and multi-core hardware. We will establish infrastructure for a higher-level of collaborative analysis, building on the successful patterns used for the Higgs boson discovery and enabling a deeper communication between the theoretical community and the experimental community. DIANA's products will sit in the ROOT framework, already used by our community of more than 10000 particle and nuclear physicists. By improving interoperability with the larger scientific software ecosystem, DIANA will incorporate best practices and algorithms from other disciplines into HEP. Similarly, we will make our computing insights, tools, and novel ideas related to collaborative analysis, standards for data preservation, and best practices for treating software as a research product available to the larger scientific community. Acknowledgement This project is supported by National Science Foundation grants ACI-1450310, ACI-1450319, ACI-1450323, and ACI-1450377 . Any opinions, findings, conclusions or recommendations expressed in this material are those of the developers and do not necessarily reflect the views of the National Science Foundation.","tags":"pages","title":"DIANA Overview"},{"url":"/","text":"The primary goal of DIANA/HEP (Data Intensive ANAlysis for High Energy Physics) is developing state-of-the-art tools for experiments which acquire, reduce, and analyze petabytes of data. Improving performance, interoperability, and collaborative tools through modifications and additions to packages broadly used by the community will allow users to more fully exploit the data being acquired at CERN's Large Hadron Collider (LHC) and other facilities. Focus Areas RIO - ROOT I/O technology Emerging Architectures - vectorization, parallelization, GPUs (GooFit) Interoperability - particularly with the scientific Python ecosystem Collaborative Analysis Tools - RooFit, RooStats, HepData interfaces, and analysis preservation DIANA/HEP is funded by the National Science Foundation's Software Infrastructure for Sustained Innovation (SI2) program. Tweets by @diana_hep !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/&#94;http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+\"://platform.twitter.com/widgets.js\";fjs.parentNode.insertBefore(js,fjs);}}(document,\"script\",\"twitter-wjs\"); We're hiring! Learn more","tags":"pages","title":"Home"},{"url":"/","text":"PROJECT PERSONNEL Peter Elmer (Lead PI) - Princeton University Department of Physics Kyle Cranmer (Co-PI) - New York University Department of Physics & Center for Data Science Jinyang Li (Senior Personnel) - New York University Computer Science Department Michael D. Sokoloff (Co-PI) - University of Cincinnati Main Campus Department of Physics Brian P. Bockelman (Co-PI) - University of Nebraska-Lincoln Department of Computer Science and Engineering Openings RIO Emerging Architectures Interoperability with the Scientific Python Ecosystem Collaborative Analysis Tools","tags":"pages","title":"Job Opportunities"},{"url":"/Hello World.html","text":"Initial post for DIANA-HEP. Status of build: To do: setup DNS for www.diana-hep.org subdomain using this guide setup DNS for diana-hep.org apex domain using this guide ok, working with .net currently, need to decide. Progress: Created DIANA-HEP GitHub Organization Using Pelican to generate website Using Travis to build website -- how-to deploying to GitHub pages http://diana-hep.github.io created CNAME file to use custom url diana-hep.org Check math: \\(pp \\to \\tilde{\\chi}_1&#94;0 \\tilde{\\chi}_1&#94;\\pm\\) Check code def main (): print 'welcome to Pelican' Check embed ipython notebook Particle physicisits primarily use ROOT for the data analysis framework. Part of that framework is a package called RooFit statistical modeling and fitting package. I have contributed to this package and added a layer on top called RooStats that provides with statistical inference in both frequentist and Bayesian paradigms based on statistical models made with RooFit. These are the tools that were used to claim the discover the Higgs boson, and those statistical models get pretty complicated . Here I demonstrate a simple example of RooFit's ability to create a statistical model, generate some simulated data, fit that data, create the profile likelihood, and provide a covariance matrix from the likelihood fit. ROOT is a C++ library, but it has python bindings known as PyROOT. In [1]: import ROOT import rootnotes #for plotting with iPython c1 = rootnotes . default_canvas () Here we create a \"workspace\" object that provides a factory with a convenient syntax for statistical models and variables. The workspace also provides an I/O mechanism to read/write statistical models and data to/from files. In this example, we create a mixture model of a falling exponential distribution and a Gaussian for a variable x. This is really a marked Poisson process, because in addition to the pdf on x, we also encode that we expect s=50 events from the Gaussian and b=100 events from the falling exponential. In [2]: w = ROOT . RooWorkspace () w . factory ( 'Gaussian::g(x[-5,5],mu[-3,3],sigma[1])' ) w . factory ( 'Exponential::e(x,tau[-.5,-3,0])' ) w . factory ( 'SUM::model(s[50,0,100]*g,b[100,0,1000]*e)' ) w . Print () #this isn't displaying in iPython TClass::TClass:0: RuntimeWarning: no dictionary for class stack<RooAbsArg*,deque<RooAbsArg*> > is available Now that we have made the mdoel, we can generate some fake data, make a plot of the data, fit the model to that data, and overlay the fitted model in the plot In [3]: x = w . var ( 'x' ) pdf = w . pdf ( 'model' ) frame = x . frame () data = pdf . generate ( ROOT . RooArgSet ( x )) data . plotOn ( frame ) fitResult = pdf . fitTo ( data , ROOT . RooFit . Save ()) pdf . plotOn ( frame ) frame . Draw () c1 Out[3]: We can check the value of the parameters after the fit In [4]: mu = w . var ( 'mu' ) print 'best fit value of mean for Gaussian is' , mu . getVal (), '±' , mu . getError () best fit value of mean for Gaussian is 0.324840840875 ± 0.158716435359 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Blog","title":"Hello World"}]}